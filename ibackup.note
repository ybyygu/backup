#+TITLE: 系统数据自动备份
#+SETUPFILE: ~/Notes/common.org
#+TODO: TODO | DONE(@)
#+PROPERTY: mkdirp yes
#+PROPERTY: padline no

#+name: UPDATED
#+BEGIN_SRC rst
Updated: 2015-04-22 14:57
#+END_SRC

* 摘要
  * 将isync-data下的数据 *实时* 同步至isync-backup下
  * 在isync-snapshots下做快照, 保存版本信息
  * 按指数衰减算法清理isync-snapshots下的快照

* [2/3] Memo
** TODO [2015-04-18 Sat] isync-data不应该放在etc这个目录下, 可能导致无穷递归.
   放在/backup下要好很多.
** DONE [#B] [2013-07-23 Tue] lsyncd 2.1新版 无法使用之前写的config文件, 需要升级 :Action:
   - State "DONE"       from "TODO"       [2015-04-18 Sat 11:43]
** [2012-06-29 Fri]: 2.0.7版更新. 以后有空了注意与rsyncssh.lua同步

   需要处理rsyncExitCodes之类的东西. rsyncExitCodes = default.rsyncExitCodes,

** DONE [2012-06-17 Sun]: 使用牛顿冷却公式来处理文件备份的问题 [[http://songshuhui.net/archives/67391][URL]]
   - State "DONE"       from "TODO"       [2015-04-19 Sun 13:32] \\
     已应用.
** [2011-09-05 Mon]: 注意exclude文件里不能有空行, 否则所有文件都会被排除掉.

** [2011-05-19 Thu] update to lsyncd-2.0
   新版的优点:
   * 可以处理move事件, 不用像以前那样进行"delete here >> copy there"的
     操作.
   * 配置文件使用lua语法.

* 架构规划
  1. 数据目录: source_directories
     1) 基于目录+软链接的方式管理起来更方便直观些.
     2) 源目录通过软链接到source_rootdir(isync-data)下
        : isync-data/note --> ~/Notes
        其中~/Notes是真正要备份的目录: source_directory

  2. 目标目录(备份数据至..): backup_directory
     - backup_rootdir(/btrfs/backup): 用于数据备份的根目录, 所有源目录都将同步其下的
       子目录
     - backup_directory: 真正用于数据备份的目录
       如1.2中的例子:
       : backup_directory = /btrfs/backup/note
     - 如果backup_rootdir是btrfs文件系统的一个子卷(subvolume), 则可基
       于基snapshot功能, 做版本备份(TimeMachine).
     - snapshot_rootdir (/btrfs/TimeMachine): 用于在其下存储btrfs子卷
       (/btrfs/backup)快照. 应为btrfs文件系统下一普通目录.
     - 基于日期的快照命名: snapshot_rootdir/day/time
       : /btrfs/TimeMachine/2011-09-04/22:13
     - 快照清理
       - 需要自动清理旧的备份(指数衰减)
* BTRFS
  1. BTRFS 做增量备份: [[https://btrfs.wiki.kernel.org/index.php/Incremental_Backup][incremental backup]]
     "-o" 做只读版本

* install
  1. aur: lsyncd
  2. 需要lua中的lfs包 lua51-filesystem
* logging
** 相关资料: [[http://victorlin.me/posts/2012/08/26/good-logging-practice-in-python][Good logging practice in Python]]
** guts中的设置(很多问题)
   #+NAME: bad-logger
   #+BEGIN_SRC python :results output
     import logging
     import sys

     LogThemeNull = logging.Formatter(
         " %(message)s")
     LogThemeSimple = logging.Formatter(
         "[%(levelname)s] %(message)s")
     LogThemeClean = logging.Formatter(
         "[%(name)s|%(lineno)04d %(levelname)s] %(message)s")
     LogThemeClean2 = logging.Formatter(
         "[%(name)s|%(lineno)04d %(levelname)5s %(asctime)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S")
     LogThemeFull = logging.Formatter(
         "\n%(asctime)s - %(name)s.%(funcName)s, line %(lineno)d\n" \
         + "-"*80 + "\n [%(levelname)s] %(message)s",
         datefmt="%Y-%m-%d %H:%M:%S")

     class ConsoleHandler(logging.StreamHandler):
         """
         log messages to console screen
         >> direct logging.error and above to stderr, others to stdout
         """
         def __init__(self, *args, **kwargs):
             logging.StreamHandler.__init__(self, *args, **kwargs)

         def emit(self, record):
             if record.levelno >= logging.WARN:
                 self.stream = sys.stderr
             else:
                 self.stream = sys.stdout
             logging.StreamHandler.emit(self, record)

     def setup_logger(name=None, theme="null", logfile=None, verbose=True, root=False):
         """ if name is empty, you get the root logger
         @root: root logger of not
         """
         
         Themes = {"clean":LogThemeClean,
                   "clean2": LogThemeClean2,
                   "simple":LogThemeSimple,
                   "null":LogThemeNull,
                   "full":LogThemeFull
                   }

         # make levelname shorter
         if theme in ("clean", "simple"):
             logging.addLevelName(logging.DEBUG, "D")
             logging.addLevelName(logging.INFO, "I")
             logging.addLevelName(logging.WARN, "W")
             logging.addLevelName(logging.ERROR, "E")

         if name and not root:
             logger = logging.getLogger(name)
         else:
             logger = logging.getLogger()
             
         logger.setLevel(logging.DEBUG)
         
         # keep console screen clean
         console_hdlr = ConsoleHandler()
         if verbose:
             console_hdlr.setLevel(logging.DEBUG)
         else:
             console_hdlr.setLevel(logging.INFO)
         theme = Themes[theme.lower()]
         console_hdlr.setFormatter(theme)
         # logger.addHandler(console_hdlr)

         # send debug info to logfile in full details
         if logfile is None:
             logfile = "/dev/null"
         else:
             dirname = os.path.dirname(logfile)
             if dirname and not os.path.exists(dirname):
                 os.makedirs(dirname)
         # use delay to avoid empty log file
         # TODO: delay argument requires python27
         # log_hdlr = logging.FileHandler(logfile, mode="w", delay=True)
         log_hdlr = logging.FileHandler(logfile, mode="w")
         log_hdlr.setLevel(logging.DEBUG)
         log_hdlr.setFormatter(Themes["clean2"])
         logger.addHandler(log_hdlr)

         # replace excepthook with logger
         def log_exception(exc_type, exc_value, traceback):
             logger.error("Oops! We run into troubles:\n>>>")
             logger.error(exc_value, exc_info=(exc_type, exc_value, traceback))
         sys.excepthook = log_exception
      
         return logger

     logger = setup_logger("test")
     logger.info("here")

#+END_SRC

** configurations
   #+name: yaml-conf
   #+begin_src yaml
     version: 1
     disable_existing_loggers: true

     root:
       level: !!python/name:logging.NOTSET
       handlers: [console, logfile]

     handlers:
         logfile:
           class: logging.FileHandler
           filename: snapman.log
           formatter: simpleFormatter
           delay: True
           level: !!python/name:logging.NOTSET
         # direct all logging msg to stdout instead of stderr
         console:
           class: logging.StreamHandler
           stream: ext://sys.stdout
           formatter: simpleFormatter
           level: !!python/name:logging.NOTSET

     formatters:
       simpleFormatter:
         class: !!python/name:logging.Formatter
         format: '%(levelname)-05s %(funcName)s@l%(lineno)-4d %(message)s'
         datefmt: '%d/%m/%Y %H:%M:%S'
   #+end_src
   
** basic-logger
   #+NAME: basic-logger
   #+HEADER: :noweb yes
   #+BEGIN_SRC python :results output :session logger
     def get_logger(name=None, debug=True):
         import logging
         import logging.config
         import StringIO
         import yaml
         
         yaml_conf = """
     <<yaml-conf>>
     """
         
         config = yaml.load(StringIO.StringIO(yaml_conf))
         logging.config.dictConfig(config)
         
         logger = logging.getLogger(name or __name__)
         level = logging.DEBUG if debug else logging.INFO
         logger.setLevel(level)
         
         return logger
         
   #+END_SRC

   #+RESULTS: basic-logger

   #+NAME: basic-logger-test
   #+HEADER: :tangle log.py
   #+BEGIN_SRC python :results output :noweb yes
     <<basic-logger>>

     def test_logger():
         logger.debug("msg from a function")

     print("good")
     logger = get_logger()
     logger.debug("debug here")
     logger.info("info here")
     logger.error("error test")
     test_logger()


   #+END_SRC

   #+RESULTS: basic-logger-test
   : good
   : DEBUG <module>@l51   debug here
   : INFO  <module>@l52   info here
   : ERROR <module>@l53   error test
   : DEBUG test_logger@l47   msg from a function

* 备份清理算法
** 指数衰减.
   随着时间的增加, 备份保留的意义递减. 这被称为牛顿冷却定律, 其实与玻
   尔兹曼分布一回事.
*** evaluate-decay
    #+NAME: evaluate-decay
    #+BEGIN_SRC python :results output :session test :cache no
      import math

      def evaluate_decay_score(elapsed, kbt=600*0.083145):
          """ use Boltzmann distribution instead """
          
          assert elapsed >= 0 and kbt > 0
          
          score = math.exp(-1*elapsed / kbt)
          return score

      def evaluate_decay_area(point_from, point_to, kbt=600*0.083145):
          """ the Boltzmann distribution area (integration) """
          
          if point_from > point_to:
              point_from, point_to = point_to, point_from
          
          s1 = math.exp(-1*point_from / kbt)
          s2 = math.exp(-1*point_to / kbt)
          return (s1 - s2)*kbt
    #+END_SRC

    测试下看:
    #+BEGIN_SRC python :results output :cache no :noweb eval
      <<evaluate-decay>>

      print(evaluate_decay_score(0, 300))
      print(evaluate_decay_score(20, 30))
      print(evaluate_decay_area(0, 24, 80))
      print(evaluate_decay_area(0, 500, 80))
    #+END_SRC

    #+RESULTS:
    : 1.0
    : 0.367879441171
    : 50.5696447063
    : 79.9270494428

    如选kbt=80, 一天(24h)中可保留约51个备份, 约下的分布在约三周的时间
    (500h)长度的序列里.

** 备份清理
   1. 各个备份, 按时间序, 组成一列.
      : dir1, dir2, dir3, ..., dir9
   2. 从序列中最近的开始, 向后选择一个, 二者做比较.
      : dir1 vs dir2
      : dir1 vs dir3
   3. 通过积分公式, 容易算出这两个备份所组成的时间区域容许的最大备份数
      目alowed_snapshots.
   4. 如果allowed_snapshots < 1, 选择下一个备份, 继续2和3步. 直到最大
      两个备份的时间间隔足够的长, 满足指数衰减的要求. 然后循环下去, 构
      建一个稀疏些的备份序列.
      : dir1, dir4, dir9, ...
   5. 清除非保留队列里的备份. 任务完成.
*** tests    
    #+BEGIN_SRC python :noweb eval
      <<imports>>

      <<trim-snapshots>>

      for adir, bdir in zip(adirs, bdirs):
          score = calc_snapshot_score(adir, bdir)
          #print("{}/{}: {:.2f}".format(adir, bdir, score))
          choices.append((adir, bdir))
          weights.append(score)
                  
      ichoices = iter(choices)
      for c in bichoose(ichoices):
          print(c)
          
    #+END_SRC

** 权重选择
   备份过程暂时用不上.

*** 基于权重选择单一项(赌轮盘算法)

    #+NAME: weighted-choose-one
    #+BEGIN_SRC python :session test :results output
      import random
      import bisect
      import operator

      def accumulate(iterable, func=operator.add):
          it = iter(iterable)
          total = next(it)
          yield total
          for element in it:
              total = func(total, element)
              yield total

      def weighted_choose_one(choices, weights):
          """ select single one based on their weights """
          
          assert len(choices) == len(weights)
          cumdist = list(accumulate(weights))
          x = random.random() * cumdist[-1]
          return bisect.bisect(cumdist, x)

    #+END_SRC
    
    #+RESULTS: weighted-choose-one

*** 基于权重选择多个项
   #+NAME: weighted-choose
   #+BEGIN_SRC python :session test :results output
     def weighted_choose(choices, weights, ncount):
         """ choose n-choices one time according their weights """
         
         assert len(choices) > ncount
         
         chosen = []
         for it in range(ncount):
             idx = weighted_choose_one(choices, weights)
             chosen.append(choices[idx])
             del choices[idx]
             del weights[idx]
         return sorted(chosen)

   #+END_SRC
   
   #+RESULTS: weighted-choose

* lsyncd
** 启动lsyncd
#+BEGIN_SRC sh :tangle scripts/start-lsyncd.sh :shebang #! /usr/bin/env bash :results none
  # get real script path
  script_path="$0"
  [[ -h "$script_path" ]] && script_path=$(readlink "$script_path")

  script_root=$(cd $(dirname "$script_path"); pwd)
  echo "script root is: \"$script_root\""
  cd "$script_root"

  while true; do
      lsyncd -nodaemon -delay 30 -log all lsyncd.lua
      # sleep 5
      exit 0
  done
#+END_SRC

** lsyncd配置文件
*** 笔记
   需要安装: lua-filesystem

   见源代码中default.lua, default.checkgauge
#+BEGIN_EXAMPLE
--
-- used to ensure there aren't typos in the keys
--
default.checkgauge = {
	action        =  true,
	checkgauge    =  true,
	collect       =  true,
	delay         =  true,
	exitcodes     =  true,
	init          =  true,
	maxDelays     =  true,
	maxProcesses  =  true,
	onAttrib      =  true,
	onCreate      =  true,
	onModify      =  true,
	onDelete      =  true,
	onStartup     =  true,
	onMove        =  true,
	prepare       =  true,
	source        =  true,
	target        =  true,
}
#+END_EXAMPLE
   1. sync函数是主要的入口
   2. 几个重要的子函数
      1. init
      2. action
      3. collect
      4. prepare
   3. 默认的事件处理函数
      1. OnStartup
      2. OnAttrib
      3. OnCreate
      4. OnDelete
      5. OnModify
      6. OnMove
   4. default.action ==> onMove, onDelete ...
*** src
#+BEGIN_SRC lua :tangle scripts/isync.lua
-----
-- My configuration file for lsyncd.
-- This needs lsyncd 2.1
--
--

require("lfs")

local source_rootdir = lfs.currentdir() .. "/scratch"
local backup_rootdir = "/btrfs/backup"
local snapshot_rootdir = "/btrfs/TimeMachine"


settings {
    logfile    = "/tmp/lsyncd.log",
    statusFile = "/tmp/lsyncd.status",
	statusInterval = 1,
    nodaemon   = true,
    maxDelays = 15,
}

---
-- record file change events and make btrfs snapshots accordingly
--
iman = {
    ---
    -- take snapshot when max_hits reached
    max_hits = 3,

    current_hits = 0,

    ---
    -- make btrfs snapshots
    --
    take_snapshot = function(event)
        log("Normal", "taking snapshot...")
        log("Normal", "./take-snapshot.py " .. backup_rootdir .. " " .. snapshot_rootdir)
        os.execute("./take-snapshot.py " .. backup_rootdir .. " " .. snapshot_rootdir)
     end,

    ---
    -- record hits
    --
    hit = function(event)
        iman.current_hits = iman.current_hits + 1
        log("Normal", "hitted as " .. iman.current_hits)
        ---
        -- reset hits
        --
        if iman.current_hits >= iman.max_hits then
            iman.current_hits = 0
            iman.take_snapshot(event)
        end
    end
}

local isync = default.rsync

isync.checkgauge.onMove = true

-- called when a process exited.
-- this can be a rsync command, the startup rsync or the postcmd
isync.collect = function(agent, exitcode)
    log("Normal", "collecting here")
	if not agent.isList and agent.etype == 'Init' then
        log("Normal", "init procedure")
    else
        log("Normal", "iman hit")
        iman.hit(agent)
    end
    --- everything else, forward to default collection handler
    return default.collect(agent,exitcode)
end


for afile in lfs.dir(source_rootdir) do
    if afile ~= '.' and afile ~= '..' then
        local path = source_rootdir .. "/" .. afile
        local attr = lfs.attributes(path, "mode")
        if attr == "directory" then
            source_dir = path
            target_dir = backup_rootdir .. "/" .. afile
            -- log("Normal", source_dir .. " ==> " .. target_dir )
            sync{isync, source=source_dir, target=target_dir, excludeFrom = "isync.exclude"}
        end
    end
end

#+END_SRC
* snapman.py [[elisp:(org-babel-tangle)][tangle]]
** outline
#+NAME: overview
#+HEADER: :session test
#+HEADER: :shebang #! /usr/bin/env python2
#+HEADER: :results output
#+BEGIN_SRC python :noweb yes :tangle scripts/snapman.py
  <<header>>

  <<imports>>

  <<setup-logger>>

  <<evaluate-decay>>

  <<snapshot-manager>>

#+END_SRC

#+RESULTS:
: 
: ... ... ... ... ... ... ... ... ... ... ... ... >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> >>> ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... >>> ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... >>> ... ... 0
** imports
#+NAME: imports
#+BEGIN_SRC python :session test
  from __future__ import division

  import os
  import sys
  import time
  import datetime
  import subprocess
  import math
  import random
  import re
  import logging

#+END_SRC

#+RESULTS: imports

** header
#+NAME: header
#+BEGIN_SRC python
  # -*- coding: utf-8 -*-
  #====================================================================#
  #   DESCRIPTION:  btrfs snapshot dwim
  # 
  #       OPTIONS:  ---
  #  REQUIREMENTS:  ---
  #         NOTES:  ---
  #        AUTHOR:  Wenping Guo (ybyygu) 
  #         EMAIL:  winpng@gmail.com
  #       LICENCE:  GPL version 2 or upper
  #       CREATED:  2015-04-20 17:51
  #       UPDATED: 
  #====================================================================#

#+END_SRC

** setup logger
   #+NAME: setup-logger
   #+BEGIN_SRC python :noweb yes :results none
     # --------------------------------------------------------------------
     # setup global logger
     # --------------------------------------------------------------------

     <<basic-logger>>

     logger = get_logger("isync")

   #+END_SRC

** class SnapshotManager
*** UML
    #+begin_src plantuml :file test.png
      class SnapshotManager {
      + take_snapshot
      + delete_snapshot
      + trim_snapshots 
      }

      take_snapshot : dir_to_snapshot
      delete_snapshot --> dir_to_snapshot
      trim_snapshot --> dir_to_snapshot
      trim_snapshots --> delete_snapshot
      delete_snapshot --> _delete_snapshot



    #+end_src

    #+RESULTS:
    [[file:test.png]]
    
*** outline
#+NAME: snapshot-manager
#+BEGIN_SRC python :results output :session test :noweb yes
  # --------------------------------------------------------------------
  # SnapshotManager class
  # --------------------------------------------------------------------

  class SnapshotManager(object):
      def __init__(self, target_subvolume, snapshot_rootdir, max_snapshots_per_day=20, max_snapshot_hits=4, max_snapshots_total=80):
          self.target_subvolume = target_subvolume
          self.snapshot_rootdir = snapshot_rootdir
          self.max_snapshots_per_day = max_snapshots_per_day
          
          self._snapshot_hits = 0
          self.max_snapshot_hits = max_snapshot_hits
          self.max_snapshots_total = max_snapshots_total
          
      <<take-snapshot>>
      
      <<delete-snapshot>>
      
      <<trim-snapshots>>
#+END_SRC

#+RESULTS: snapshot-manager

*** take snapshot
    BTRFS 快照.
    1. 根据当前的时间, 确定快照保存的目录名: snapshot_dirname.
    2. 如果同名的快照已存在, 则不操作.

    #+NAME: take-snapshot
    #+BEGIN_SRC python :results none
      def take_snapshot(self):
          """ take one single btrfs snapshot """
          
          snapshot_parent_dir = os.path.join(self.snapshot_rootdir, time.strftime("%Y-%m-%d"))
          
          if not os.path.exists(snapshot_parent_dir):
              os.makedirs(snapshot_parent_dir)
              logger.info("Created snapshot directory: {}".format(snapshot_parent_dir))

          ##
          # take snapshot only when there is no directory named as snap_name
          # --------------------------------------------------------------------
          dirname = "{}:{:02}".format(time.strftime("%H"), int(time.strftime("%M")))
          snap_name = os.path.join(snapshot_parent_dir, dirname)
          logger.debug("snapshot directory: {}".format(snap_name))
          
          if not os.path.isdir(snap_name):
              args = "btrfs subvolume snapshot".split()
              args.append(self.target_subvolume)
              args.append(snap_name)        
              logger.info("Called with: {}".format(" ".join(args)))
              try:
                  subprocess.check_call(args)
              except subprocess.CalledProcessError:
                  logger.exception("Failed to take snapshot with btrfs!")
                  raise
          else:
              logger.debug("Delayed for {}".format(snap_name))

    #+END_SRC

*** delete snapshot
    #+NAME: delete-snapshot
    #+BEGIN_SRC python :results none
      def _delete_snapshot_by_path(self, snapshot_path):
          """ delete one single snapshot specified by snapshot_path """
          
          if not os.path.exists(snapshot_path):
              msg ="snapshot directory {} does not exists!".format(snapshot_path)
              logger.error(msg)
              raise RuntimeError(msg)

          args = "btrfs subvolume delete".split()
          args.append(snapshot_path)
          logger.debug("cmdline: {}".format(" ".join(args)))
          try:
              subprocess.check_call(args)
              logger.info("snapshot removed.")
          except subprocess.CalledProcessError:
              logger.exception("Failed to delete btrfs snapshot!")
              raise
          
      def delete_snapshot(self, snapshot):
          """ delete one single snapshot """

          if type(snapshot) not in (list, tuple):
              logger.error("wrong argument specified: {}".format(snapshot))
              return

          assert len(snapshot) == 2
          day_dir, time_dir = snapshot
          
          snapshot_path = os.path.join(day_dir, time_dir)
          logger.info("try to delete: {}/{}".format(day_dir, time_dir))
          self._delete_snapshot_by_path(snapshot_path)
          
    #+END_SRC

*** trim-snapshots
    #+NAME: trim-snapshots
    #+begin_src python
      def _snapshot_dir_to_datetime(self, day_dir, time_dir):
          return datetime.datetime.strptime("{}/{}".format(day_dir, time_dir), "%Y-%m-%d/%H:%M")

      def _calc_snapshot_score(self, day_dir, time_dir):
          now = datetime.datetime.now()
          delta = now - self._snapshot_dir_to_datetime(day_dir, time_dir)
          hours = delta.total_seconds() / 3600
          logger.debug(hours)
          return evaluate_decay_score(hours, self.max_snapshots_total)

      def _calc_allowed_snapshots(self, choices):
          """ calculate how many snapshots allowed to keep """
          
          assert len(choices) >= 2
          first, last = choices[0], choices[-1]
          
          now = datetime.datetime.now()
          d1 = (now - self._snapshot_dir_to_datetime(*last)).total_seconds() / 3600
          d2 = (now - self._snapshot_dir_to_datetime(*first)).total_seconds() / 3600
          return evaluate_decay_area(d1, d2, self.max_snapshots_total)

      def _bichoose(self, ichoices, current=None):
          if current is None:
              choice1 = next(ichoices)
          else:
              choice1 = current
              
          finished = False
          for choice2 in ichoices:
              allowed = self._calc_allowed_snapshots([choice1, choice2])
              logger.debug("{} {} {:.1f}".format(choice1[-1], choice2[-1], allowed))
              if allowed >= 1:
                  score1 = self._calc_snapshot_score(*choice1)
                  score2 = self._calc_snapshot_score(*choice2)
                  #idx = weighted_choose_one([choice1, choice2], [score1, score2])
                  #yield choice1 if idx == 0 else choice2
                  yield choice1
                  break
          else:
              finished = True
              yield choice1
              
          if not finished:
              for c in self._bichoose(ichoices, current=choice2):
                  yield c

      def _get_snapshots(self):
          """ get all available snapshots on the disk """
          
          snapshots = []
          for adir in os.listdir(self.snapshot_rootdir):
              snap_parentdir_path = os.path.join(self.snapshot_rootdir, adir)
              for bdir in os.listdir(snap_parentdir_path):
                  try:
                      before = self._snapshot_dir_to_datetime(adir, bdir)
                      snapshots.append((adir, bdir))
                  except ValueError:
                      logger.error("Failed to parse time stamp: {}/{}".format(adir, bdir))
                      continue
          
          return snapshots
          
      def trim_snapshots(self, snapshots=[]):
          """ trim outdated snapshots with some intelligence """
          
          # optional argument: to make it easy for testing
          snapshots = snapshots or self._get_snapshots()
          
          if snapshots:
              logger.info("Loaded {} snapshots.".format(len(snapshots)))
          else:
              logger.warn("No available snapshots found.")
              return
          
          ##
          # trim snapshots in a smart way
          # --------------------------------------------------------------------
          ichoices = iter(snapshots)
          snapshots_all = set(snapshots)
          snapshots_to_keep = []
          
          assert len(snapshots_all) == len(snapshots)
          
          for c in self._bichoose(ichoices):
              snapshots_to_keep.append(c)
              
          snapshots_to_delete = snapshots_all - set(snapshots_to_keep)
          nd = len(snapshots_to_delete)
          assert nd >= 0

          if nd == 0:
              logger.info("Nothing to do.")
              return
          
          logger.info("{} snapshots will be removed from history.".format(nd))
          for asnap in snapshots_to_delete:
              self.delete_snapshot(asnap)
                  
          return
              
   #+end_src

    #+RESULTS: trim-snapshots
    
*** tests
     - Note taken on [2015-04-21 Tue 15:45] \\
       tests怎么加才合理?
       
     #+tblname: tbl-dirs
     |      adirs | bdirs |
     |------------+-------|
     | 2015-04-19 | 22:00 |
     | 2015-04-19 | 21:01 |
     | 2015-04-18 | 20:02 |
     | 2015-04-18 | 21:03 |
     | 2015-04-17 | 12:04 |
     | 2015-04-17 | 12:05 |
     | 2015-04-17 | 12:06 |
     | 2015-04-16 | 11:07 |
     | 2015-04-13 | 12:08 |
     | 2015-03-13 | 12:09 |
     
     #+HEADER: :var adirs=tbl-dirs[,0]
     #+HEADER: :var bdirs=tbl-dirs[,1]
     #+BEGIN_SRC python :noweb yes :results output :dir scripts/
       from snapman import SnapshotManager

       snapshots = []
       for adir, bdir in zip(adirs, bdirs):
           snapshots.append((adir, bdir))

       snapman = SnapshotManager("/btrfs/backup", "/tmp/scratch")
       #snapman.take_snapshot()
       #snapman.delete_snapshot("/tmp/scratch/aa")
       snapman.trim_snapshots(snapshots)
     #+END_SRC

     #+RESULTS:

** main function
#+NAME: main-function
#+BEGIN_SRC python :results output :noweb yes

  def main(argv=None):
      import optparse
      
      if argv == None: argv = sys.argv
      
      # parsing cmdline
      cmdl_usage = 'usage: %prog [options]...'
      cmdl_version = "%prog " + <<VERSION>> + "; updated at: " + <<UPDATED>>
      cmdl_parser = optparse.OptionParser(usage=cmdl_usage, \
                                          version=cmdl_version, \
                                              conflict_handler='resolve')
      cmdl_parser.add_option('-h', '--help', 
                              action='help',
                              help='print this help text and exit')
      cmdl_parser.add_option('-v', '--version', 
                              action='version', 
                              help='print program version and exit')
      (cmdl_opts, cmdl_args) = cmdl_parser.parse_args()
      
      return 0

  if __name__ == '__main__':
      main()

#+END_SRC

#+RESULTS: main-function

* Local variables
# Local Variables:
# time-stamp-format: "%:y-%02m-%02d %02H:%02M"
# time-stamp-pattern: "100/^Updated: %%$"
# End:
